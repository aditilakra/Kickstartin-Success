{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Kickstartin' Success\n",
    "\n",
    "In this study, we will explore [data](https://webrobots.io/kickstarter-datasets/) on Kickstarter projects and build a model to predict campaign success or failure as well as explore the drivingfactors.\n",
    "\n",
    "Content:\n",
    "* [Introduction](#intro)\n",
    "* [Initialization](#init)\n",
    "* [Predictive Model](#model)\n",
    "* [Evaluation](#eval)\n",
    "* [Future Work](#fw)\n",
    "\n",
    "<h4><center>...</center></h4>\n",
    "\n",
    "<a id='intro'><h2>Introduction</h2></a>\n",
    "\n",
    "Nowadays if you have a great idea but not the means, crowdsourcing on Kickstarter sounds compelling. However, only 44% percent of campaigns on Kickstarter reached their funding goal. Before you jump into Kickstarter, find out if it's the right platform for you. What makes a successful Kickstarter campaign? What is a realistic funding goal? By leveraging the tools and power of data analytics, we seek to answer questions and build a model to predict the success (or failure) of a potential project.\n",
    "\n",
    "<h2><a id='intro'>Initialization</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import os, json\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import ttest_ind, f_oneway, lognorm, levy, skew, chisquare\n",
    "from sklearn.preprocessing import normalize, scale\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A large dataset provided by [Web Robots](https://webrobots.io/kickstarter-datasets/) was used to train the model. The dataset contains kickstarter campaigns collected monthly through webscrapping. Each dataset is composed of all kickstarter campaigns up to a set maximum for each category. We utilized the data collected up until January 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Download dataset\n",
    "# Check if the dataset is present on local disk and load it\n",
    "if os.path.exists('Kickstarter_2018-01.csv'):\n",
    "    data = pd.read_csv('Kickstarter_2018-01.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 194475\n",
      "Number of columns:  86\n"
     ]
    }
   ],
   "source": [
    "# Print the size of the dataset\n",
    "print (\"Number of rows:\", data.shape[0])\n",
    "print (\"Number of columns: \", data.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id='model'>Predictive Model</a></h2>\n",
    "\n",
    "**Summary**\n",
    "\n",
    "The initial dataset contained 194475 transactions with 86 time-series, categorical and numerical variables. In order to build the final model, the process is brokened down into (1) [Data cleaning](#s1), (2) [Feature engineering](#s2) (3) [Exploratory data analysis](#s3) and (4) [Building the model](#s4).\n",
    "\n",
    "**Note:** The code to make predictions is provided in a function as success_predictor.py\n",
    "\n",
    "<h3><a id='s1'>Data Cleaning</a></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function to clean a loaded dataset\n",
    "\n",
    "def clean_data(mydata):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function cleans the input dataframe adata:\n",
    "    . \n",
    "    \n",
    "    input:\n",
    "        mydata: pandas.dataframe\n",
    "    output: \n",
    "        pandas.dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    data = adata.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><a id='s3'>Feature Engineering</a></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create predict variable: success\n",
    "\n",
    "successful = data['state'] == \"successful\"\n",
    "failed = data['state'] == \"failed\"\n",
    "\n",
    "data = data.loc[failed | successful]\n",
    "\n",
    "data['success'] = data['state'].astype('category')\n",
    "data['success'] = pd.Categorical.from_array(data.success).codes\n",
    "data.success.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><a id='s1'>Exploratory Data Analysis</a></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><a id='s4'>Building the Model</a></h3>\n",
    "\n",
    "Firstly, functions for cross-validation and parameter optimization were defined such that they are applicable on either classification or regression algorithm\n",
    "\n",
    "<h4><center>...</center></h4>\n",
    "\n",
    "This function (**modelfit**) train the model given as 'alg' by performing cross-validation. It works on both regression and classification\n",
    "\n",
    "* **alg**: sklearn model\n",
    "* **dtrain**: pandas.DataFrame, training set\n",
    "* **predictors**: list, labels of features (column names) to be used in the model training\n",
    "* **target**: str, target variable\n",
    "* **scoring_method**: str, method to be used by the cross-validation to valuate the model\n",
    "* **performCV**: bool, perform Cv or not\n",
    "* **printFeatureImportance**: bool, plot histogram of features importance or not\n",
    "* **cv_folds**: int, degree of cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# import scikit learn libraries\n",
    "from sklearn import cross_validation, metrics   #model optimization and valuation tools\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "\n",
    "# define a function that help to train models and perform cv\n",
    "def modelfit(alg,dtrain,predictors,target,scoring_method,performCV=True,printFeatureImportance=True,cv_folds=5):\n",
    "\n",
    "    # train the algorithm on data\n",
    "    alg.fit(dtrain[predictors],dtrain[target])\n",
    "    \n",
    "    #predict on train set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    if scoring_method == 'roc_auc':\n",
    "        dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    \n",
    "    #perform cross-validation\n",
    "    if performCV:\n",
    "        cv_score = cross_validation.cross_val_score(alg,dtrain[predictors],dtrain[target],cv=cv_folds,scoring=scoring_method)\n",
    "        \n",
    "        #print model report\n",
    "        print (\"\\nModel report:\")\n",
    "        if scoring_method == 'roc_auc':\n",
    "            print (\"Accuracy: %.4f\" % metrics.accuracy_score(dtrain[target].values,dtrain_predictions))\n",
    "            print (\"AUC Score (Train): %.4f\" % metrics.roc_auc_score(dtrain[target], dtrain_predprob))\n",
    "        if (scoring_method == 'mean_squared_error'):\n",
    "            print (\"Accuracy: %.4f\" % metrics.mean_squared_error(dtrain[target].values,dtrain_predictions))\n",
    "    if performCV:\n",
    "        print (\"CV Score: Mean : %.5g | Std : %.5g | Min : %.5g | Max : %.5g \\n\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))\n",
    "    \n",
    "    #print feature importance\n",
    "    if printFeatureImportance:\n",
    "        if dir(alg)[0] == '_Booster': #runs only if alg is xgboost\n",
    "            feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "        else:\n",
    "            feat_imp = pd.Series(alg.feature_importances_,predictors).sort_values(ascending=False)\n",
    "        feat_imp.plot(kind='bar',title='Feature Importances')\n",
    "        plt.ylabel('Feature Importe Score')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function, (**optimize_num_trees**), is used to tune paremeters of a predictive algorithm\n",
    "\n",
    "* **alg**: sklearn model,\n",
    "* **param_test**: dict, parameters to be tuned\n",
    "* **scoring_method**: str, method to be used by the cross-validation to valuate the model\n",
    "* **train**: pandas.DataFrame, training data\n",
    "* **predictors**: list, labels to be used in the model training process. They should be in the column names of dtrain\n",
    "* **target**: str, target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# optimize n_estimator through grid search\n",
    "def optimize_num_trees(alg,param_test,scoring_method,train,predictors,target):\n",
    "    gsearch = GridSearchCV(estimator=alg, param_grid = param_test, scoring=scoring_method,n_jobs=2,iid=False,cv=5)\n",
    "    gsearch.fit(train[predictors],train[target])\n",
    "    return gsearch\n",
    "\n",
    "# plot optimization results\n",
    "def plot_opt_results(alg):\n",
    "    cv_results = []\n",
    "    for i in range(len(param_test['n_estimators'])):\n",
    "        cv_results.append((alg.grid_scores_[i][1],alg.grid_scores_[i][0]['n_estimators']))\n",
    "    cv_results = pd.DataFrame(cv_results)\n",
    "    plt.plot(cv_results[1],cv_results[0])\n",
    "    plt.xlabel('# trees')\n",
    "    plt.ylabel('score')\n",
    "    plt.title('optimization report')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Model: Gradient Boosting\n",
    "\n",
    "* Optimized number of trees: TBD\n",
    "* Optimized predictors (in order of importance):     \n",
    "    * Category.id\n",
    "    * Goal\n",
    "* ROC-AUC of test: TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing the classifier...\n",
      "\n",
      "Search grid results:\n",
      "params (best): 70\n",
      "score (best): 0.8201\n",
      "\n",
      "Model report:\n",
      "Accuracy: 0.7896\n",
      "AUC Score (Train): 0.8824\n",
      "CV Score: Mean : 0.82014 | Std : 0.010446 | Min : 0.80194 | Max : 0.82927 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAE3CAYAAABFIV02AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18f22b6e588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Processing time: 0:00:06.046340\n"
     ]
    }
   ],
   "source": [
    "## OPTIMIZATION & TRAINING OF THE CLASSIFIER\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "print (\"Optimizing the classifier...\")\n",
    "\n",
    "train = data.copy() # make a copy of the training set\n",
    "# since the dataset is too big for my system, select a small sample size to carry on training and 5 folds cross validation\n",
    "train = train.loc[np.random.choice(train.index,size=5000,replace=False)]\n",
    "target = 'success' # set target variable - it will be used later in optimization\n",
    "\n",
    "tic = dt.datetime.now() # initiate the timing\n",
    "# for predictors start with candidates identified during the EDA\n",
    "predictors = ['category.id',\n",
    "              'goal']\n",
    "\n",
    "# optimize n_estimator through grid search\n",
    "param_test = {'n_estimators': list(range(30,151,20))} # define range over which number of trees is to be optimized\n",
    "\n",
    "# initiate classification model\n",
    "model_cls = GradientBoostingClassifier(\n",
    "    learning_rate=0.1, # use default\n",
    "    min_samples_split=2,# use default\n",
    "    max_depth=5,\n",
    "    max_features='auto',\n",
    "    subsample=0.8, # try <1 to decrease variance and increase bias\n",
    "    random_state = 10)\n",
    "\n",
    "# get results of the search grid\n",
    "gs_cls = optimize_num_trees(model_cls,param_test,'roc_auc',train,predictors,target)\n",
    "print(\"\\nSearch grid results:\")\n",
    "print(\"params (best):\", gs_cls.best_params_['n_estimators']) \n",
    "print(\"score (best): %.4f\" % gs_cls.best_score_)\n",
    "\n",
    "# cross validate the best model with optimized number of estimators\n",
    "modelfit(gs_cls.best_estimator_,train,predictors,target,'roc_auc')\n",
    "     \n",
    "print (\"\\n Processing time:\", dt.datetime.now()-tic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><center>...</center></h4>\n",
    "\n",
    "We now know the optimum parameter!\n",
    "\n",
    "**Let’s test it by doing prediction on a test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.7265 \n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "indices = data.index[~data.index.isin(train.index)]\n",
    "test = data.loc[np.random.choice(indices,size=5000,replace=False)]\n",
    "\n",
    "ypred = gs_cls.best_estimator_.predict(test[predictors])\n",
    "\n",
    "print(\"ROC AUC: %.4f \" % metrics.roc_auc_score(ypred,test.success))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
